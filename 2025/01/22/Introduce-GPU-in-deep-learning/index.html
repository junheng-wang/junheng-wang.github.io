<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><!-- hexo injector head_begin start -->
<link rel="stylesheet" href="/css/bilicard.css">
<style type="text/css">.douban-card-block {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    max-height: 400px;
}

.douban-card {
    display: flex;
    margin: 30px 10px;
    padding: 15px;
    border-radius: 15px;
    position: relative;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    color: antiquewhite;
    text-decoration: none;
}

.douban-card:hover {
    text-decoration: none;
}

.douban-card-bgimg {
    position: absolute;
    width: 115%;
    height: 115%;
    filter: blur(15px) brightness(0.6);
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-img {
    position: relative;
    height: 130px;
    width: 80px;
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-left:hover .douban-card-img {
    filter: blur(5px) brightness(0.6);
    transform: perspective(800px) rotateX(180deg);
}

.douban-card-left .douban-card-img {
    transition: all 500ms ease;
}

.douban-card-left {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.douban-card-left .douban-card-status {
    height: 130px;
    width: 80px;
    text-align: center;
    font-weight: bold;
    position: absolute;
    left: 0;
    top: 30%;
    transform: rotateX(180deg);
    backface-visibility: hidden;
    transition: all 500ms ease;
}

.douban-card-left:hover .douban-card-status {
    transform: perspective(800px) rotateX(0deg);
}

.douban-card-right {
    position: relative;
    display: flex;
    flex-direction: column;
    margin-left: 12px;
    font-size: 16px;
    font-family: "Courier New", Courier, monospace;
    line-height: 1.3;
    color: antiquewhite;
}

.douban-card-item {
    margin-top: 4px;
}
</style><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深度学习中的显卡介绍 | 君恒的博客</title><meta name="author" content="君恒"><meta name="copyright" content="君恒"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="1 用于深度学习的GPU介绍1.1 目前常用于深度学习的GPU型号和性能参数 补充说明：  1.2 显卡选购建议1.2.1 入门级 - 初学者或轻度用户如果你刚开始接触深度学习，或者只是做一些简单的实验和小规模模型训练，那么以下显卡可能就足够了：  1.2.2 中级 - 研究员或开发者对于那些需要更强大的计算能力来进行更复杂的模型训练或研究工作的人群来说，可以考虑以下显卡：  1.2.3 高级&#x2F;专">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习中的显卡介绍">
<meta property="og:url" content="http://example.com/2025/01/22/Introduce-GPU-in-deep-learning/index.html">
<meta property="og:site_name" content="君恒的博客">
<meta property="og:description" content="1 用于深度学习的GPU介绍1.1 目前常用于深度学习的GPU型号和性能参数 补充说明：  1.2 显卡选购建议1.2.1 入门级 - 初学者或轻度用户如果你刚开始接触深度学习，或者只是做一些简单的实验和小规模模型训练，那么以下显卡可能就足够了：  1.2.2 中级 - 研究员或开发者对于那些需要更强大的计算能力来进行更复杂的模型训练或研究工作的人群来说，可以考虑以下显卡：  1.2.3 高级&#x2F;专">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic1.imgdb.cn/item/67a6af93d0e0a243d4fcdbf0.png">
<meta property="article:published_time" content="2025-01-22T02:46:16.000Z">
<meta property="article:modified_time" content="2025-02-09T10:09:11.788Z">
<meta property="article:author" content="君恒">
<meta property="article:tag" content="计算机">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="硬件">
<meta property="article:tag" content="GPU">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic1.imgdb.cn/item/67a6af93d0e0a243d4fcdbf0.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深度学习中的显卡介绍",
  "url": "http://example.com/2025/01/22/Introduce-GPU-in-deep-learning/",
  "image": "https://pic1.imgdb.cn/item/67a6af93d0e0a243d4fcdbf0.png",
  "datePublished": "2025-01-22T02:46:16.000Z",
  "dateModified": "2025-02-09T10:09:11.788Z",
  "author": [
    {
      "@type": "Person",
      "name": "君恒",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/butterfly-icon.png"><link rel="canonical" href="http://example.com/2025/01/22/Introduce-GPU-in-deep-learning/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习中的显卡介绍',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a1e626d0e0a243d4fbcc56.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pic1.imgdb.cn/item/67a6af0dd0e0a243d4fcdbc6.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">君恒的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">深度学习中的显卡介绍</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">深度学习中的显卡介绍</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-01-22T02:46:16.000Z" title="发表于 2025-01-22 10:46:16">2025-01-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-09T10:09:11.788Z" title="更新于 2025-02-09 18:09:11">2025-02-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/">计算机与编程学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BB%8B%E7%BB%8D/">计算机介绍</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BB%8B%E7%BB%8D/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E4%BB%8B%E7%BB%8D/">计算机硬件介绍</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">11.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>37分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2025-02-09 18:09:11&quot;}" hidden></div><h1 id="1-用于深度学习的GPU介绍"><a href="#1-用于深度学习的GPU介绍" class="headerlink" title="1 用于深度学习的GPU介绍"></a>1 用于深度学习的GPU介绍</h1><h2 id="1-1-目前常用于深度学习的GPU型号和性能参数"><a href="#1-1-目前常用于深度学习的GPU型号和性能参数" class="headerlink" title="1.1 目前常用于深度学习的GPU型号和性能参数"></a>1.1 目前常用于深度学习的GPU型号和性能参数</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122132526446-1653093349.png"><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122143120655-1500705632.png"></p>
<p>补充说明：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122143533665-1205926068.png"></p>
<h2 id="1-2-显卡选购建议"><a href="#1-2-显卡选购建议" class="headerlink" title="1.2 显卡选购建议"></a>1.2 显卡选购建议</h2><h3 id="1-2-1-入门级-初学者或轻度用户"><a href="#1-2-1-入门级-初学者或轻度用户" class="headerlink" title="1.2.1 入门级 - 初学者或轻度用户"></a>1.2.1 入门级 - 初学者或轻度用户</h3><p>如果你刚开始接触深度学习，或者只是做一些简单的实验和小规模模型训练，那么以下显卡可能就足够了：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122150555080-1422318081.png"></p>
<h3 id="1-2-2-中级-研究员或开发者"><a href="#1-2-2-中级-研究员或开发者" class="headerlink" title="1.2.2 中级 - 研究员或开发者"></a>1.2.2 中级 - 研究员或开发者</h3><p>对于那些需要更强大的计算能力来进行更复杂的模型训练或研究工作的人群来说，可以考虑以下显卡：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122150925178-965391835.png"></p>
<h3 id="1-2-3-高级-专业级-高端研究机构或企业"><a href="#1-2-3-高级-专业级-高端研究机构或企业" class="headerlink" title="1.2.3 高级/专业级 - 高端研究机构或企业"></a>1.2.3 高级/专业级 - 高端研究机构或企业</h3><p>当涉及到非常大的数据集、极其复杂的模型架构以及需要快速迭代和高吞吐量时，应该选择最顶级的专业级显卡：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122151337225-1813608360.png"></p>
<h1 id="2-CUDA概念介绍"><a href="#2-CUDA概念介绍" class="headerlink" title="2 CUDA概念介绍"></a>2 CUDA概念介绍</h1>  <div class="bvideo"><a href="//www.bilibili.com/video/BV1DFg8eDELg" target="_blank">
        <div class="bvideo-box">
            <div class="bvideo-cover">
                <div class="cover-default"></div>
                <div class="bvideo-cover-layer" style="background-image:url(https://images.weserv.nl/?url=http://i1.hdslb.com/bfs/archive/ffbf8e395913cff83180585475a71e6e71ebf7b2.jpg)">
                    <i class="icon-video"></i>
                </div>
                <span class="duration">00:07:26</span>
            </div>
            <div class="bvideo-info">
                <p class="title">13-大模型是如何在GPU中运行的</p>
                <p class="card-status">
                    <span class="play-num">
                        <i class="fa fa-youtube-play"></i>
                        <span>8919</span></span>
                    <span>
                        <i class="fa fa-list-alt"></i>
                        <span>5</span></span></p>
                <div class="partition">
                    <label class="card-label">视频</label>
                    <label class="up-label"></label>
                    <label class="up-name">泡澡的龙</label>
                </div>
                <div class="actions hide"></div>
            </div>
        </div>
    </a></div> </br>

  <div class="bvideo"><a href="//www.bilibili.com/video/BV1Jx4y1S7de" target="_blank">
        <div class="bvideo-box">
            <div class="bvideo-cover">
                <div class="cover-default"></div>
                <div class="bvideo-cover-layer" style="background-image:url(https://images.weserv.nl/?url=http://i2.hdslb.com/bfs/archive/19713b43fb063e9ab2c60898bc6d48e979bf200d.jpg)">
                    <i class="icon-video"></i>
                </div>
                <span class="duration">00:53:04</span>
            </div>
            <div class="bvideo-info">
                <p class="title">CUDA 简明教程</p>
                <p class="card-status">
                    <span class="play-num">
                        <i class="fa fa-youtube-play"></i>
                        <span>5211</span></span>
                    <span>
                        <i class="fa fa-list-alt"></i>
                        <span>8</span></span></p>
                <div class="partition">
                    <label class="card-label">视频</label>
                    <label class="up-label"></label>
                    <label class="up-name">大模型成长之路</label>
                </div>
                <div class="actions hide"></div>
            </div>
        </div>
    </a></div>
<h2 id="2-1-转载自其他网站的Cuda概念"><a href="#2-1-转载自其他网站的Cuda概念" class="headerlink" title="2.1 转载自其他网站的Cuda概念"></a>2.1 转载自其他网站的Cuda概念</h2><table><td style="word-wrap:break-word;word-break:break-all;" width=100%; bgcolor=HoneyDew><font size="3">
<font color=red><strong>🐹 什么是CUDA：</strong> </font></br>

CUDA —— 英伟达2006年推出的计算API，相当于是一种可以调用英伟达GPU的一个平合。一般计算机最重要的芯片有两个：CPU和GPU。CPU是中央处理器，GPU是图形处理器。</br>

编程语言（C/C++等）只能调用CPU，不能调用GPU。我们想让GPU强大的并行化能力充分发挥，编写一些可以并行化的程序在GPU上运行能够快速获得运行结果，所以<strong>需要一个在编程语言（C/C++等）和底层GPU这个物理芯片之间有一个可以沟通连接的东西</strong>，因此英伟达NVIDIA搞出了一个叫做<font color=red><strong>Cuda的平台</strong></font>。简单来说，可以认为Cuda是对C/C++语言进行了扩展，允许开发者编写运行在NVIDIA GPU上的代码。</br>

有了这个平台，你就可以使用编程语言（C/C++等）调用GPU处理大量的并行化任务，而不需要重新设计一个全新的能直接在GPU上直接运行的编程语言，节省了大量的学习成本。有了Cuda平台，就可以使得显卡不仅仅是进行图像像素等的处理，还能进行一些更加通用的运算，比如人工智能等算法需要大量的矩阵运算，这需要很强的并行化处理能力来加快运算，于是我们可以利用Cuda编写程序让这部分需要并行运算的代码在GPU上跑，而不是在并行化能力较弱的CPU上跑。</br>

<!DOCTYPE html>
<html lang="zh-CN">
<body style="font-family: Arial, sans-serif; background-color: #f4f4f9; padding: 20px;">
    <a href="https://www.bilibili.com/video/BV1Fn4y1972c" target="_blank" 
       style="display: inline-block; padding: 10px 20px; margin-top: 20px;
              background-color: #007bff; color: white; text-decoration: none; 
              border-radius: 5px; transition: background-color 0.3s ease;">
        什么是CUDA - 苦魔-浪人 - 哔哩哔哩
    </a>
</body>
</html>

</font></td></table>

<table><td style="word-wrap:break-word;word-break:break-all;" width=100%; bgcolor=HoneyDew><font size="3">
<font color=red><strong>🎅 Cuda是什么：</strong> </font></br>

没有CUDA就没有今天人工智能产业的繁荣，那CUDA它是个啥、它是如何诞生的。</br>

我们先从老黄和他的英伟达说起。黄仁勋1963年生于台南，1993年喜欢游戏的黄仁勋和另外两位芯片设计师Chris Malachowsky、Curtis Priem共同创立了英伟达，他们的眼光瞄准了正在蓬勃成长的个人电脑与游戏机市场，此时一些3D游戏开始崭露头角，而3D游戏必须有专业的图形显示处理器来帮助CPU加速图像渲染，这也就是我们今天常说的显卡原型。显卡中的核心就是图形计算器GPU，不过GPU这个词语出现和流行要晚一点。1999年英伟达发布其革命性产品 —— <strong>Geforce 256</strong>，其芯片采用220纳米制造，拥有2300万个晶体管，并首次把以往需要CPU处理的坐标转换和光源计算直接集成到显卡这个硬件中。这款显卡计算性能大幅跃升的同时减少了游戏对CPU计算的依赖，它也因此常被宣称为世界上第一个GPU。这时期接连涌现的GPU，为了满足市场对画面真实感的需求，允许开发人员编写在每个像素上运行的程序，这些程序很简单，可能只有几条指令，但是它们在屏幕上的每个像素背后运行：</br>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122110524971-1067628694.png" style="zoom:60%">

想象一下，如果一个游戏画面是100万像素，每个像素每秒运行60次，那么这个游戏画面本质上是一个大规模并行的程序，而这种大规模的并行计算让眼尖的人看到了其中蕴含的线性代数的矩阵乘法的影子，而涉及这类数学的领域往往都是数值建模、科学计算等，而今天极为重要的人工智能更是离不开这类数学。</br>

能不能把GPU从专用的图形计算变为适合这类数学的通用计算呢？当然可能有人这时候会想起电脑的中央处理器CPU就是通用计算，刚刚提到的科学计算人工智能等等不能用CPU算吗？</br>
答案是：能是能，只是虽然CPU的核心计算和处理复杂任务的能力相比GPU更强，但CPU核心的数量比GPU少得多：</br>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122111303311-173261623.png" style="zoom:60%">

> PS：既然GPU核心这么多，可能会有人想把CPU做大，给CPU堆核心数量不行吗？</br>
>
> 回答：物理特性限制，cpu不能做那么大。良品率等原因导致核心大小和数量有极限，一般cpu是要比gpu物理尺寸大的，显卡只是散热模具大，核心和cpu差不多大，其他的你想象成主板也可以。</br>

CPU更适合做一个接一个的串行指令，GPU更适合做同时的并行指令，所以GPU的这种能力更适合。但是此时的程序员想在GPU上编程进行通用计算是很难的事情，想要将图形处理器从游戏渲染部署应用到一般计算领域，这就需要把这些通用计算的算法转化映射到这些GPU的纹理、三角形、像素等图形基元。而这种任务即便是对高级的图形开发人员来说也很难。</br>

斯坦福大学图形实验室的伊恩·巴克不畏难，他带领团队搞了一个<strong> BrookGPU项目</strong> ，这个项日主要就是研究在GPU上进行通用编程并为开发人员提供更方便的GPU编程工具。这个项目在ATI(今AMD)、英伟达、IBM、索尼以及国防部幸能源部等机构的技术和资金支持下取得了不错的成果。他们通过引入Brook编程语言，使得C语言可以拓展涵盖简单的数据并行构造，从而实现GPU作为流处理协处理器的通用计算功能。</br>

而老黄也看到了这个项目的潜力，因为显卡想模拟显示更加真实的现实世界，就需要引入更多的物理规律，而这些规律的科学计算很依赖GPU的通用计算能力，所以老黄想借助伊恩·巴克，把英伟达的GPU打造成强大的超级计算机。伊恩·巴克毕业后顺势加入了英伟达，并从04年开始主导新项目——<font color=red><strong>CUDA(统一计算设备架构, Compute Unified Device Architeeture)</strong></font>。这是一种并行计算架构和编程模型，专门用于英伟达的GPU。<strong>通过CUDA，开发人员可以基于C语言等编程语言拓展，编写可以调用GPU进行通用计算的程序</strong>。但是Cuda的科学计算功能对于当时大部分买来打游戏的消费者来说压根用不到，英伟达一度要破产。直到2011年曾经因曼哈顿计划建立的橡树岭国家实验室正在升级打造超级计算机泰坦，他们看到了GPU作为通用计算的价值，所以采购了大量英伟达的GPU，泰坦也是世界上第一台以通用图形处理器作为主要数据处理器的超级计算机。并在2012年11月到2013年6月间，保持了世界上最快超级计算机的称号。</br>

<!DOCTYPE html>
<html lang="zh-CN">
<body style="font-family: Arial, sans-serif; background-color: #f4f4f9; padding: 20px;">
    <a href="https://www.bilibili.com/video/BV1hb4y1P7j9" target="_blank" 
       style="display: inline-block; padding: 10px 20px; margin-top: 20px;
              background-color: #007bff; color: white; text-decoration: none; 
              border-radius: 5px; transition: background-color 0.3s ease;">
        英伟达的王牌杀手：CUDA的诞生 - 哔哩哔哩
    </a>
</body>
</html>

</font></td></table>

<table><td style="word-wrap:break-word;word-break:break-all;" width=100%; bgcolor=HoneyDew><font size="3">
<font color=red><strong>🚀 一文揭开NVIDIA CUDA神秘面纱：</strong> </font></br>

今天我们来聊一下人工智能生态相关技术：用于加速构建AI核心算力的GPU编程框架 —— CUDA。</br>

你一定听说过CUDA，并了解这玩意与NVIDIA GPU密切相关。然而，关于CUDA的具体定义和功能，许多人仍然心存疑惑，一脸懵逼。CUDA是一个与GPU进行通信的库吗？如果是，它属于C++还是 Python库？或者，CUDA实际上是一个用于GPU的编译器？了解这些问题有助于更好地掌握CUDA的核心特性及其在GPU加速中的作用。</br>

CUDA，全称为 “ Compute Unified Device Architecture”，即“计算统一设备架构”，是NVIDIA推出的一套强大并行计算平台和编程模型框架，为开发人员提供了加速计算密集型应用的完整解决方案。<strong>CUDA包含运行时内核、设备驱动程序、优化库、开发工具和丰富的API组合，使得开发人员能够在支持CUDA的GPU上运行代码</strong>，大幅提升应用程序的性能。这一平台尤为适合用于<strong>处理大规模并行任务</strong>，如深度学习、科学计算以及图像处理等领域。</br>

通常而言，“CUDA” 不仅指平台本身，也可指为充分利用NVIDIA GPU的计算能力而编写的代码，这些代码多采用C++和Python等语言编写，以充分发挥GPU加速的优势。借助CUDA，开发人员能够更加轻松地将复杂的计算任务转移至GPU运行，极大提升应用程序的运行效率。</br> 

因此，总结起来，可以得出如下结论：CUDA不仅仅是一个简单的库，它是一个完整的平台，为开发者提供了利用GPU进行高效并行计算的全方位支持。这个平台的核心组件包括：</br> 
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122122612020-1063566655.png" style="zoom:45%">

<strong> CUDA到底是什么：</strong></br> 
（1）CUDA C/C++：这是CUDA为并行编程所扩展的C++语言，专为在GPU上编写并行代码而设计。开发者可以使用熟悉的C++语法结构，通过特定的编程模型定义GPU任务，让代码更高效地在多线程环境中执行。</br> 
（2）CUDA 驱动程序：这一组件连接操作系统与GPU，提供底层硬件访问接口。驱动程序的主要作用是管理CPU与GPU之间的数据传输，并协调它们的计算资源。它确保了硬件和操作系统的兼容性，是CUDA代码高效运行的基础。</br> 
（3）CUDA 运行时库（cudart）：运行时库为开发者提供了丰富的API，便于管理GPU内存、启动GPU内核（即并行任务）、同步线程等。它简化了开发者的工作流程，使得在GPU上运行并行程序的流程更加流畅和高效。</br> 
（4）CUDA 工具链（ctk）：包括编译器、链接器、调试器等工具，这些工具用于将CUDA代码编译成GPU可执行的二进制指令。工具链中的编译器将C++代码和CUDA内核代码一同处理，使其适应GPU的架构；而调试器和分析工具帮助开发者优化性能和排查问题。</br> 

相关的环境变量可参考如下：</br> 
1. <code>$CUDA_HOME</code>是系统CUDA的路径，看起来像<code>/usr/local/cuda</code>，它可能链接到特定版本<code>/usr/local/cuda-X.X</code>。</br> 
2. <code>`$LD_LIBRARY_PATH/`</code>是一个帮助应用程序查找链接库的变量。您可能想要包含<code>$CUDA_HOME/lib</code>的路径。</br> 
3. <code>`$PATH`</code>应该包含一个通往<code>$CUDA_HOME/bin</code>的路径。</br> 

借助这一完整的开发平台，开发者能够充分挖掘NVIDIA GPU的计算潜力，将复杂的并行计算任务高效地分配至GPU上执行，从而实现应用程序性能的极大提升。</br> 

<strong>CUDA是如何工作的</strong> 

现代GPU由数千个小型计算单元组成，这些单元被称为CUDA核心。CUDA核心能够高效并行工作，使GPU能够快速处理那些可以分解为多个小型独立操作的任务。这种架构使得GPU不仅适用于图形渲染任务，也适用于计算密集型的科学计算和机器学习等非图形任务。</br>  

作为NVIDIA提供的一个计算平台和编程模型，CUDA专门为GPU开放了这些强大的并行处理能力。通过CUDA，开发者可以编写代码，将复杂的计算任务移交给GPU。以下是CUDA的工作原理：</br>  

&nbsp;&nbsp;&nbsp;&nbsp;并行处理</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CUDA将计算任务分解为多个可以独立运行的小任务，并将这些任务分配到多个CUDA核心上并行执行。这样一来，与传统CPU顺序执行的模式相比，GPU可以在相同时间内完成更多的计算，从而极大地提升计算效率。</br>

&nbsp;&nbsp;&nbsp;&nbsp;线程和块的架构</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在CUDA编程模型中，计算任务被进一步划分为线程，每个线程独立处理一部分数据。这些线程被组织成块，每个块中包含一定数量的线程。这种层次化结构不仅便于管理海量线程，还提高了执行效率。多个线程块可以同时运行，使得整个任务可以快速并行完成。</br>

&nbsp;&nbsp;&nbsp;&nbsp;SIMD架构</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CUDA核心采用<strong>单指令多数据(Single Instruction Multiple Data，SIMD)</strong>架构。这意味着单条指令可以对多个数据元素同时执行操作。例如，可以用一条指令对大量数据元素进行相同的计算，从而加快数值计算的速度。这种架构对矩阵运算、向量处理等高并行任务极为高效，特别适用于深度学习模型训练、图像处理和模拟仿真等领域。</br>

基于这些特性，CUDA不仅为高性能并行计算提供了直接途径，也将NVIDIA GPU的强大计算潜力拓展至科学计算、人工智能、图像识别等领域。</br>  

<strong>CUDA编程模型</strong> </br>

在CUDA编程中，开发者通常需要编写两部分代码：<font color=blue><strong>主机代码（Host Code）</strong></font>和<font color=purple><strong>设备代码（Device Code）</strong> </font>。主机代码在CPU上运行，负责与GPU进行交互，包括数据传输和资源管理；而设备代码则在GPU上执行，承担主要计算任务。二者相互配合，充分利用CPU和GPU的协同处理能力，以达到高效并行计算的目的。</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue><strong>主机代码（Host Code）</strong></font></br>
主机代码运行在CPU上，负责控制整个程序的逻辑流程。它管理CPU和GPU之间的数据传输，分配和释放GPU资源，并配置GPU内核参数。这部分代码不仅定义了如何组织数据并将其发送到GPU，还包含了启动设备代码的指令，从而让GPU接管计算密集的任务。主机代码起到管理和协调的作用，确保CPU与GPU之间的高效协作。</br>

此部分包括数据传输、内存管理、以及启动 GPU 内核等，具体功能可参考如下所示：</br>
1. 数据传输管理：主机代码负责在 CPU 和 GPU 之间传输数据。由于 CPU 和 GPU 通常使用不同的内存系统，主机代码需要在两者之间复制数据。例如，将需要处理的数据从主机内存（CPU 内存）传输到设备内存（GPU 内存），并在处理完成后将结果从 GPU 内存传回 CPU 内存。这种数据传输是耗时的，因此在实际应用中需要尽量减少传输频率，并优化数据大小，以降低延迟。</br>
2. 内存分配与管理：主机代码分配 GPU 内存空间，为后续的计算提供储存资源。CUDA API 提供了多种内存管理函数（如 cudaMalloc 和 cudaFree），允许开发者在 GPU 上动态分配和释放内存。合理的内存分配策略可以有效提高内存使用效率，防止 GPU 内存溢出。</br>
3. 内核配置与调度：在主机代码中，开发者可以配置内核启动参数（如线程数和线程块数）并决定内核在 GPU 上的执行方式。通过优化这些参数，主机代码能够显著提升程序的执行效率</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=purple><strong>设备代码（Device Code）</strong> </font></br>
<strong>设备代码编写的核心部分是在GPU上执行的计算函数</strong>，通常被称为<font color=orange><strong>内核（Kernel）</strong></font>。每个内核函数在GPU的众多CUDA核心上并行执行，能够快速处理大量数据。设备代码专注于数据密集型的计算任务，在执行过程中充分利用GPU的并行计算能力，使得计算速度比传统的串行处理有显著提升。</br>

设备代码定义了GPU的计算逻辑，使用CUDA内核来并行处理大量数据。</br>
1. 内核函数（Kernel Function）：<strong>设备代码的核心是内核函数</strong>，即在GPU的多个线程上同时执行的函数。内核函数由<code>__global__</code>关键字标识，表示该函数将在设备端（GPU）执行。内核函数与普通的 C/C++ 函数不同，它必须是无返回值的，因为所有输出结果都要通过修改传入的指针或GPU内存来传递。</br>
2. 线程和线程块的组织：在设备代码中，计算任务被分解为多个线程，这些线程组成线程块（Block），多个线程块组成一个线程网格（Grid）。CUDA 提供了 threadIdx、blockIdx 等内置变量来获取线程的索引，从而让每个线程在数据中找到属于自己的计算任务。这种方式使得设备代码可以非常高效地并行处理数据集中的每个元素。</br>
3. 并行算法优化：在设备代码中，CUDA编程可以实现多个并行优化技术，如减少分支、优化内存访问模式（如减少全局内存访问和提高共享内存利用率），这些优化有助于最大化利用GPU计算资源，提高设备代码执行速度。</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=DeepPink><strong>内核启动</strong></font></br>
内核启动是CUDA编程的关键步骤，由主机代码启动设备代码内核，在GPU上触发执行。内核启动参数指定了GPU上线程的数量和分布方式，使内核函数可以通过大量线程并行运行，从而加快数据处理速度。通过适当配置内核，CUDA编程能以更优的方式利用GPU资源，提高应用的计算效率。</br>

在整个体系中，这一步骤至关重要，它控制了设备代码的并行性、效率及运行行为。具体可参考如下：</br>
1. 内核启动语法：CUDA 使用特殊的语法<code><<<Grid, Block>>></code>启动内核函数。例如：<code>kernel<<<numBlocks, threadsPerBlock>>>(parameters);</code>，其中<code>numBlocks</code>表示线程块的数量，<code>threadsPerBlock</code>表示每个线程块中包含的线程数。开发者可以根据数据集的大小和GPU的计算能力选择合适的线程块和线程数量。</br>
2. 并行化控制：通过指定线程块数和线程数，内核启动控制了GPU的并行粒度。较大的数据集通常需要更多的线程和线程块来充分利用GPU的并行能力。合理配置内核启动参数，可以平衡GPU的并行工作负载，避免资源浪费或过载现象。</br>
3. 同步与异步执行：内核启动后，GPU可以异步执行任务，CPU继续进行其他操作，直至需要等待GPU完成。开发者可以利用这种异步特性，使程序在CPU和GPU间并行执行，达到更高的并行效率。此外，CUDA提供了同步函数（如<code>cudaDeviceSynchronize</code>），确保CPU在需要时等待GPU完成所有操作，避免数据不一致的问题。</br>

通过有效协调这三者，CUDA编程能够实现对数据密集型任务的高速并行处理，为高性能计算提供了一个极具扩展性的解决方案。</br>

<strong>CUDA内存层次结构体系</strong></br>

在CUDA编程中，GPU内存的结构是多层次的，具有不同的速度和容量特性。CUDA提供了多种内存类型，用于不同的数据存储需求。合理利用这些内存可以显著提升计算效率。以下是各类内存的详细描述：</br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue><strong>全局内存（Global Memory）</strong></font>
全局内存是GPU上容量最大的存储空间，通常为几GB，并且是GPU的主要数据存储区。全局内存可以被所有线程访问，也可以与CPU共享数据，但其访问速度相对较慢（相对于其他GPU内存类型而言），因此需要避免频繁访问。数据传输操作也较耗时，因此全局内存常用于存储较大的数据集，但会优先考虑数据访问的批处理或其他缓存策略来减少其频繁调用。</br>

通常而言，全局内存主要适用于存储程序的大部分输入输出数据，尤其是需要GPU和CPU共享的大容量数据。</br>

示例：在矩阵乘法中，两个矩阵的元素可以存储在全局内存中，以便所有线程都可以访问。</br>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">matrixMultiplication</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        sum += A[row * N + i] * B[i * N + col];</span><br><span class="line">    &#125;</span><br><span class="line">    C[row * N + col] = sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=purple><strong>共享内存（Shared Memory）</strong></font></br>
共享内存是分配在GPU每个线程块内部的高速缓存，其访问速度远高于全局内存，但容量较小（通常为每块48 KB或更少）。共享内存是线程块内线程共享的，适合存储需要在一个线程块内频繁访问的数据。由于它存储在各自的块内，每个块内的线程可以在共享内存中快速读写数据，从而减少对全局内存的访问。</br>

相对于全局内存，共享内存更多适用于多线程间的数据交换，尤其是需在一个线程块内反复使用的数据。</br>

示例：在矩阵乘法中，A和B的子块可以加载到共享内存中，以便线程块中的所有线程都可以快速访问。</br>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">float</span> sharedA[TILE_SIZE][TILE_SIZE];</span><br><span class="line">__shared__ <span class="type">float</span> sharedB[TILE_SIZE][TILE_SIZE];</span><br></pre></td></tr></table></figure>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=DarkTurquoise><strong>本地内存（Local Memory）</strong></font></br>
本地内存是分配给每个线程的私有内存，主要用于存储线程的私有变量。尽管称为“本地”，它实际上是分配在全局内存中，因此访问速度较慢，接近全局内存的访问速度。由于本地内存容量有限且其访问开销较高，建议只在必要时使用。</br>

通常情况下，本地内存适用于存储线程的临时变量、私有数据或不适合在寄存器中保存的数据。</br>

示例：对于复杂计算中的中间变量，可以放置在本地内存中，以便线程之间不发生冲突。</br>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> localVariable = <span class="number">0</span>;  <span class="comment">// 本地内存中的变量</span></span><br></pre></td></tr></table></figure>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color=Goldenrod><strong>常量和纹理内存（Constant and Texture Memory）</strong></font></br>

常量内存和纹理内存分别是 CUDA 提供的专用于只读数据的内存类型，具有特殊的缓存机制，能够在特定访问模式下加快数据读取。常量内存用于存储不会更改的常量数据，而纹理内存适合存储二维或三维数据，通过纹理缓存可以提高访问速度。</br>

1. 常量内存（Constant Memory）：仅可由CPU写入，但可被所有GPU线程读取。适合存储小规模的、不变的数据（如配置信息、系数等）。</br>
2. 纹理内存（Texture Memory）：专门优化以支持二维或三维数据的读取，对于非顺序或稀疏访问模式的数据（如图像数据）具有较高的访问效率。</br>

示例：在图像处理应用中，将像素数据加载到纹理内存中，让 GPU 利用其特定的缓存机制来优化访问效率。</br>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="type">float</span> constData[<span class="number">256</span>];  <span class="comment">// 常量内存</span></span><br><span class="line"></span><br><span class="line">cudaArray* texArray;</span><br><span class="line">cudaChannelFormatDesc channelDesc = <span class="built_in">cudaCreateChannelDesc</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line"><span class="built_in">cudaMallocArray</span>(&amp;texArray, &amp;channelDesc, width, height);  <span class="comment">// 纹理内存</span></span><br></pre></td></tr></table></figure>

<strong>小结</strong></br>

CUDA平台为开发人员提供了对CUDA GPU并行计算资源的深度访问，允许直接操作GPU的虚拟指令集和内存。通过使用CUDA，GPU可以高效地处理数学密集型任务，从而释放CPU的计算资源，使其能够专注于其他任务。这种架构与传统GPU的3D图形渲染功能有着本质的区别，开创了GPU在计算领域的新用途。</br>

在CUDA平台的架构中，CUDA核心是其核心组成部分。每个CUDA核心都是一个独立的并行处理单元，负责执行各种计算任务。GPU中的CUDA核心数量越多，它能够并行处理的任务就越多，从而显著提升计算性能。通过这种并行计算，CUDA平台能够在复杂的计算过程中实现大规模任务的并行处理，提供卓越的性能和高效性。</br>


<!DOCTYPE html>
<html lang="zh-CN">
<body style="font-family: Arial, sans-serif; background-color: #f4f4f9; padding: 20px;">
    <a href="https://news.qq.com/rain/a/20241110A01ZQO00" target="_blank" 
       style="display: inline-block; padding: 10px 20px; margin-top: 20px;
              background-color: #007bff; color: white; text-decoration: none; 
              border-radius: 5px; transition: background-color 0.3s ease;">
        一文揭开 NVIDIA CUDA 神秘面纱 - 架构驿站 - 腾讯网
    </a>
</body>
</html>

</font></td></table>

<table><td style="word-wrap:break-word;word-break:break-all;" width=100%; bgcolor=HoneyDew><font size="3">
<font color=red><strong>🌈 关于CUDA理解的其他连接：</strong> </font></br>  

<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2414140">英伟达CUDA介绍及核心原理 - 腾讯云</a></br>

<a target="_blank" rel="noopener" href="https://blog.csdn.net/j8267643/article/details/136200206">【深入理解 Linux 调度（GPU）虚拟化】【转载】- CSDN</a></br>

<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/649201833">CUDA到底是什么东西，能不能通俗易懂地解释一下？ - 知乎</a></br>

<a target="_blank" rel="noopener" href="https://blog.csdn.net/chenby186119/article/details/144557642">CUDA（Compute Unified Device Architecture）介绍 - CSDN</a></br>

<a target="_blank" rel="noopener" href="https://www.bilibili.com/opus/880800210758926361">Nvidia的cuda是如何垄断的，三个软件护城河，一个芯片和软件协同 - 哔哩哔哩</a></br>

<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YN4y1K719">一张图看懂CPU、GPU、NPU - 哔哩哔哩</a></br>

<a target="_blank" rel="noopener" href="https://space.bilibili.com/517221395/lists/1388713?type=season">合集·【AI芯片】GPU详解 - ZOMI酱 - 哔哩哔哩视频</a></br>

<a target="_blank" rel="noopener" href="https://space.bilibili.com/517221395/lists/1420176?type=season">合集·【AI芯片】NPU芯片 - ZOMI酱 - 哔哩哔哩视频</a></br>

<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1wbcdeWENh">都是处理器！CPU GPU NPU的区别到底是什么？- 哔哩哔哩</a></br>

<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV15Q4y1i7Bp/?share_source=copy_web">【PyTorch】B站首个，终于有人把 GPU/ CUDA/ cuDNN 讲清楚了- 哔哩哔哩</a></br>

</font></td></table>

<h2 id="2-2-关于BrookGPU的介绍"><a href="#2-2-关于BrookGPU的介绍" class="headerlink" title="2.2 关于BrookGPU的介绍"></a>2.2 关于BrookGPU的介绍</h2><h3 id="2-2-1-BrookGPU是什么"><a href="#2-2-1-BrookGPU是什么" class="headerlink" title="2.2.1 BrookGPU是什么"></a>2.2.1 BrookGPU是什么</h3><p>BrookGPU是一种针对图形处理器（GPU）的编程语言扩展，基于ANSI C(ANSI C标准,也称为C89或C90标准,是C语言的一种标准规范)语言，旨在简化和优化数据并行计算。它由斯坦福大学图形实验室开发，最初是<strong>为了在GPU上进行通用计算而设计</strong>。</p>
<ul>
<li><p><strong>核心概念</strong>，BrookGPU的核心概念包括<strong>流（Streams）</strong>和<strong>内核（Kernels）</strong>：</p>
<ol>
<li>流（Streams）：流是BrookGPU中的一种数据类型，代表一系列可以并行处理的数据。流的声明类似于C语言中的数组，但具有并行处理的特性。</li>
<li>内核（Kernels）：内核是在GPU上执行的函数，用于处理流中的数据。</li>
</ol>
</li>
<li><p><strong>设计目标</strong></p>
<ol>
<li>BrookGPU的设计目标是将GPU作为流式协处理器，通过流式编程模型将数据并行计算和算术密集型计算集成到一个熟悉的语言中。它通过编译器和运行时系统抽象化了GPU的硬件细节，使得开发者可以更方便地利用GPU的并行计算能力。</li>
</ol>
</li>
<li><p><strong>特点</strong></p>
<ol>
<li>数据并行性：允许开发者指定如何在不同数据上并行执行相同的操作。</li>
<li>算术密集型计算：鼓励开发者指定数据上的操作，以减少全局通信，增加局部计算。</li>
<li>简化编程模型：通过流和内核的概念，BrookGPU简化了GPU编程，降低了对图形硬件知识的要求。</li>
</ol>
</li>
<li><p><strong>应用场景</strong></p>
<ol>
<li>BrookGPU适用于多种高性能计算场景，如图像处理、物理模拟、傅里叶变换（FFT）等。它通过利用GPU的大规模并行性，能够显著提升计算效率。</li>
</ol>
</li>
<li><p><strong>开源与支持</strong><br>1.BrookGPU作为一个开源项目，提供了编译器和运行时系统，支持在多种GPU硬件上运行。它为开发者提供了一个通用的工具，用于探索GPU在通用计算中的潜力。</p>
</li>
</ul>
<p>总的来说，BrookGPU是早期探索GPU通用计算的重要工具之一，为后续的GPU编程模型（如CUDA）奠定了基础。 </p>
<h3 id="2-2-2-BrookGPU的底层源代码"><a href="#2-2-2-BrookGPU的底层源代码" class="headerlink" title="2.2.2 BrookGPU的底层源代码"></a>2.2.2 BrookGPU的底层源代码</h3><p>BrookGPU是一种软件，具体来说，它是一个编译器和运行时系统，用于在图形处理器（GPU）上进行通用计算。</p>
<p>BrookGPU的底层源代码主要是用<strong>C语言</strong>编写的。它的编译器（brcc）基于一个开源的C解析器cTool，并被修改以支持Brook语言的特定语法。此外，BrookGPU的运行时系统（BRT）提供了一个跨平台的接口，支持多种后端，包括OpenGL、DirectX以及CPU参考实现。</p>
<ul>
<li><p><strong>流（Streams）</strong>是BrookGPU中的一种<strong>数据结构</strong>，用于表示可以并行处理的数据集合。<strong>流的声明类似于C语言中的数组</strong>，但有一些特殊的规则和限制：</p>
<ul>
<li>流使用尖括号<code>&lt;&gt;</code>声明，例如<code>float s&lt;10, 10&gt;</code>表示一个二维流，包含100个浮点元素。</li>
<li>流的形状（Shape）指的是其维度，例如<code>&lt;10, 10&gt;</code>表示一个<code>10×10</code>的二维流。</li>
<li>流的元素只能在内核（Kernels）中访问，或用<code>streamRead</code>和<code>streamWrite</code>操作符在内存和流之间传输数据。</li>
<li>流不支持静态初始化，例如不能使用<code>float s&lt;100&gt; = &#123;1.0f, 2.0f, ...&#125;</code>的方式初始化。</li>
</ul>
</li>
<li><p><strong>内核（Kernels）</strong>是BrookGPU中的一种<strong>特殊函数</strong>，用于对流中的数据进行并行操作。内核定义和调用方式为：</p>
<ul>
<li>内核函数以<code>kernel</code>关键字声明，返回类型为<code>void</code>，并且至少有一个流参数。</li>
<li>调用内核时，BrookGPU会隐式地对流中的每个元素执行内核函数。</li>
<li>内核可以接受输入流（只读）和输出流（只写），还可以接受常量参数。</li>
</ul>
</li>
</ul>
<p>以下是一个简单的BrookGPU程序示例，展示了流和内核的使用：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一个内核函数，用于计算向量的线性组合</span></span><br><span class="line">kernel <span class="type">void</span> <span class="title function_">saxpy</span><span class="params">(<span class="type">float</span> a, float4 x&lt;&gt;, float4 y&lt;&gt;, out float4 result&lt;&gt;)</span> &#123;</span><br><span class="line">    result = a * x + y;  <span class="comment">// 对每个流元素执行操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="type">float</span> a = <span class="number">2.0f</span>;  <span class="comment">// 系数</span></span><br><span class="line">    float4 X[<span class="number">100</span>], Y[<span class="number">100</span>], Result[<span class="number">100</span>];  <span class="comment">// 主机内存中的数组</span></span><br><span class="line">    float4 x&lt;<span class="number">100</span>&gt;, y&lt;<span class="number">100</span>&gt;, result&lt;<span class="number">100</span>&gt;;  <span class="comment">// 声明流</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化数据...</span></span><br><span class="line">    <span class="comment">// 将数据从主机内存传输到流</span></span><br><span class="line">    streamRead(x, X);</span><br><span class="line">    streamRead(y, Y);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用内核函数，对流中的每个元素执行操作</span></span><br><span class="line">    saxpy(a, x, y, result);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果从流传输回主机内存</span></span><br><span class="line">    streamWrite(result, Result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在这个例子中：<ul>
<li><code>float4 x&lt;100&gt;</code>, <code>y&lt;100&gt;</code>, <code>result&lt;100&gt;</code>声明了三个流，分别用于输入和输出。</li>
<li><code>saxpy</code>内核函数对每个流元素执行操作，计算<code>a*x + y</code>。</li>
<li><code>streamRead</code>和<code>streamWrite</code>用于在主机内存和流之间传输数据。</li>
</ul>
</li>
</ul>
<p>通过流和内核的概念，BrookGPU提供了一种高效且简洁的方式来利用GPU的并行计算能力，适用于图像处理、科学计算等场景。</p>
<h1 id="3-各GPU支持的CUDA版本"><a href="#3-各GPU支持的CUDA版本" class="headerlink" title="3 各GPU支持的CUDA版本"></a>3 各GPU支持的CUDA版本</h1><h2 id="3-1-查看显卡驱动版本号"><a href="#3-1-查看显卡驱动版本号" class="headerlink" title="3.1 查看显卡驱动版本号"></a>3.1 查看显卡驱动版本号</h2><p>当显卡驱动安装完成后，需要使用<code>nvidia-smi</code>命令查看英伟达显卡驱动版本。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">显卡驱动信息，主要看driver API的CUDA版本，即Runtime API CUDA支持的最高版本</span></span><br><span class="line">nvidia-smi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当前使用的CUDA的版本</span></span><br><span class="line">nvcc -V</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看安装了几个CUDA，当前使用哪个版本的CUDA</span></span><br><span class="line">ll /usr/local/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看已安装的包的版本</span></span><br><span class="line">conda list | grep cuda</span><br><span class="line">conda list | grep torch</span><br></pre></td></tr></table></figure><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122170845475-1893288545.png" style="zoom:50%"></p>
<p>如上图所示，英伟达驱动版本为<code>520.61.05</code>，CUDA最高支持的版本为<code>11.8</code>。</p>
<h2 id="3-2-查看显卡驱动版本号和CUDA版本对应关系"><a href="#3-2-查看显卡驱动版本号和CUDA版本对应关系" class="headerlink" title="3.2 查看显卡驱动版本号和CUDA版本对应关系"></a>3.2 查看显卡驱动版本号和CUDA版本对应关系</h2><p>查看英伟达显卡驱动版本和CUDA版本的对应关系 —— 点击该链接：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html</a></p>
<p>下图为CUDA工具包和CUDA小版本兼容性所需的最低驱动程序版本：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122171215959-30652988.png"></p>
<p>由于我工作站（Ubuntu 20.04 LTS）的英伟达驱动版本为<code>520.61.05</code>，从上图可以看出，我最高可以安装的CUDA版本为<code>11.8.x</code>。（注：<code>CUDA 12.0.x</code>和<code>CUDA 12.1.x</code>都要求英伟达驱动版本大于等于<code>525.60.13</code>，因此我的<code>520.61.05</code>不符合，所以我最高只能安装<code>CUDA 11.8.x</code>的版本）。</p>
<h2 id="3-3-查看经典的CUDA版本号"><a href="#3-3-查看经典的CUDA版本号" class="headerlink" title="3.3 查看经典的CUDA版本号"></a>3.3 查看经典的CUDA版本号</h2><p>由于我们最终是要安装pytorch，因此选取合适的CUDA进行安装是有必要的。CUDA和PyTorch之间存在版本依赖关系，这是因为PyTorch可以使用CUDA加速深度学习模型的训练和推理，需要与特定版本的CUDA兼容才能正常工作。以下是CUDA和PyTorch版本之间的关系：</p>
<ul>
<li>CUDA和PyTorch的版本兼容性：<ul>
<li>不同版本的PyTorch需要与特定版本的CUDA兼容，以确保能够利用GPU的计算能力。这是因为PyTorch使用CUDA来执行深度学习操作。</li>
<li>在使用PyTorch之前，你应该查看PyTorch官方文档或GitHub仓库中的文档，以了解当前版本所支持的CUDA版本。通常，PyTorch的文档会明确说明支持的CUDA版本范围。<br>-示例：<ul>
<li>例如，如果你使用的是<code>PyTorch 1.8.0</code>，官方文档可能会明确指出支持<code>CUDA 11.1</code>，因此你需要安装<code>CUDA 11.1</code>或兼容版本的CUDA驱动来与<code>PyTorch 1.8.0</code>一起使用。</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>pytorch版本</th>
<th>torchvision版本</th>
<th>cuda版本</th>
<th>python版本</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.4.0</td>
<td>0.2.2</td>
<td>Cuda8.0 / 9.0 / 9.1</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>0.4.1</td>
<td>0.2.2</td>
<td>Cuda8.0 / 9.0 / 9.2</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.0.0</td>
<td>0.2.1</td>
<td>Cuda8.0 / 9.0 / 10.0</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.0.1</td>
<td>0.2.2</td>
<td>Cuda9.0 / 10.0</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.1.0</td>
<td>0.3.0</td>
<td>Cuda9.0 / 10.0</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.2.0</td>
<td>0.4.0</td>
<td>Cuda9.2 / 10.0</td>
<td>[3.5, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.3.0</td>
<td>0.4.1</td>
<td>Cuda9.2 / 10.0 / 10.1</td>
<td>[2.7, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.3.1</td>
<td>0.4.2</td>
<td>Cuda9.2 / 10.0 / 10.1</td>
<td>[2.7, 3.7]</td>
<td></td>
</tr>
<tr>
<td>1.4.0</td>
<td>0.5.0</td>
<td>Cuda9.2 / 10.1</td>
<td>[3.5, 3.8]</td>
<td></td>
</tr>
<tr>
<td>1.5.0</td>
<td>0.6.0</td>
<td>Cuda9.2 / 10.1 / 10.2</td>
<td>[3.5, 3.8]</td>
<td></td>
</tr>
<tr>
<td>1.5.1</td>
<td>0.6.1</td>
<td>Cuda9.2 / 10.1 / 10.2</td>
<td>[3.5, 3.8]</td>
<td></td>
</tr>
<tr>
<td>1.6.0</td>
<td>0.7.0</td>
<td>Cuda9.2 / 10.1 / 10.2</td>
<td>[3.5, 3.8]</td>
<td></td>
</tr>
<tr>
<td>1.7.0</td>
<td>0.8.1</td>
<td>Cuda10.1 / 10.2/ 11.0</td>
<td>[3.6, 3.8]</td>
<td></td>
</tr>
<tr>
<td>1.7.1</td>
<td>0.8.2</td>
<td>Cuda10.1 / 10.2 / 11.0</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.8.0</td>
<td>0.9.0</td>
<td>Cuda10.1 / 10.2 / 11.1</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.8.1</td>
<td>0.9.1</td>
<td>Cuda10.1 / 10.2 / 11.1</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.9.0</td>
<td>0.10.0</td>
<td>Cuda10.2 / 11.1</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.9.1</td>
<td>0.10.1</td>
<td>Cuda10.2 / 11.1</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.10.0</td>
<td>0.11.1</td>
<td>Cuda10.2 / 11.1 / 11.3</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.10.1</td>
<td>0.11.2</td>
<td>Cuda10.2 / 11.1 / 11.3</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.10.2</td>
<td>0.11.3</td>
<td>Cuda10.2 / 11.1 / 11.3</td>
<td>[3.6, 3.9]</td>
<td></td>
</tr>
<tr>
<td>1.11.0</td>
<td>0.12.0</td>
<td>Cuda11.1 / 11.3 / 11.5</td>
<td>[3.7, 3.10]</td>
<td></td>
</tr>
<tr>
<td>1.12.0</td>
<td>0.13.0</td>
<td>cuda10.2 / 11.3 / 11.6</td>
<td>[3.7, 3.10]</td>
<td></td>
</tr>
<tr>
<td>1.13.0</td>
<td>0.14.0</td>
<td>cuda11.6 / 11.7</td>
<td>[3.7, 3.11]</td>
<td></td>
</tr>
<tr>
<td>1.13.1</td>
<td>0.14.1</td>
<td>cuda11.6 / 11.7</td>
<td>[3.7, 3.11]</td>
<td></td>
</tr>
<tr>
<td>2.0.0</td>
<td>0.15.0</td>
<td>cuda11.7 / 11.8</td>
<td>[3.8, 3.11]</td>
<td></td>
</tr>
<tr>
<td>2.0.1</td>
<td>0.15.2</td>
<td>cuda11.7 / 11.8</td>
<td>[3.8, 3.11]</td>
<td></td>
</tr>
<tr>
<td>2.1.0</td>
<td>0.16.0</td>
<td>cuda11.8 / 12.1</td>
<td>[3.8, 3.11]</td>
<td></td>
</tr>
<tr>
<td>2.1.1</td>
<td>0.16.1</td>
<td>cuda11.8 / 12.1</td>
<td>[3.8, 3.11]</td>
</tr>
</tbody>
</table>
</div>
<h2 id="3-4-小结"><a href="#3-4-小结" class="headerlink" title="3.4 小结"></a>3.4 小结</h2><p>确定PyTorch、CUDA和显卡驱动的版本并确保它们兼容，可以按照以下步骤进行：</p>
<ul>
<li><p><strong>确定显卡驱动版本</strong>：</p>
<ul>
<li>在终端中执行<code>nvidia-smi</code>命令。这个命令会显示当前系统上的NVIDIA显卡驱动版本以及相关信息。</li>
<li>记下显示的 NVIDIA 驱动版本号。例如，版本号可能类似于<code>465.19.01</code>。</li>
</ul>
</li>
<li><p><strong>确定 CUDA 版本</strong>：</p>
<ul>
<li>通常，NVIDIA显卡驱动与CUDA版本一起安装。所以，你可以通过查看CUDA的版本来确定。</li>
<li>在终端中执行<code>nvcc --version</code>命令来查看CUDA版本。</li>
<li>记下显示的CUDA版本号。例如，版本号可能类似于<code>11.1</code>。</li>
</ul>
</li>
<li><p><strong>确定 PyTorch 版本</strong>：</p>
<ul>
<li>使用Python代码来查看PyTorch的版本：<code>import torch; print(torch.__version__)</code></li>
<li>记下显示的PyTorch版本号。例如，版本号可能类似于<code>1.8.1</code>。</li>
</ul>
</li>
<li><p><strong>检查兼容性</strong>：</p>
<ul>
<li>一旦你确定了各个组件的版本号，你可以查阅PyTorch的官方文档，了解哪个版本的PyTorch与哪个版本的CUDA和显卡驱动兼容。通常，PyTorch的文档会明确说明支持的CUDA版本范围。</li>
<li>如果你的PyTorch版本与你的CUDA版本和显卡驱动版本不兼容，你可能需要升级或降级其中一个或多个组件，以确保它们能够良好地协同工作。</li>
</ul>
</li>
</ul>
<blockquote>
<p>往往我们在实际项目时，起始首先确定的是PyTorch的版本，进而确定CUDA的版本，再根据CUDA的版本去查看自己平台的驱动是否支持。</p>
</blockquote>
<p>参考链接1：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2334017">深度学习|如何确定 CUDA+PyTorch 版本 - 腾讯云</a></p>
<h1 id="4-CUDA、CUDA-toolkit、CUDNN、NVCC关系"><a href="#4-CUDA、CUDA-toolkit、CUDNN、NVCC关系" class="headerlink" title="4 CUDA、CUDA toolkit、CUDNN、NVCC关系"></a>4 CUDA、CUDA toolkit、CUDNN、NVCC关系</h1><h2 id="4-1-CUDA-cudnn-CUDA-Toolkit-NVCC区别简介"><a href="#4-1-CUDA-cudnn-CUDA-Toolkit-NVCC区别简介" class="headerlink" title="4.1 CUDA/cudnn/CUDA Toolkit/NVCC区别简介"></a>4.1 CUDA/cudnn/CUDA Toolkit/NVCC区别简介</h2><ul>
<li>CUDA：为“GPU通用计算”构建的运算平台。</li>
<li>cudnn：为深度学习计算设计的软件库。</li>
<li>CUDA Toolkit (nvidia)： CUDA完整的工具安装包，其中提供了Nvidia驱动程序、开发CUDA程序相关的开发工具包等可供安装的选项。包括CUDA程序的编译器、IDE、调试器等，CUDA程序所对应的各式库文件以及它们的头文件。</li>
<li>CUDA Toolkit (Pytorch)： CUDA不完整的工具安装包，其主要包含在使用CUDA相关的功能时所依赖的动态链接库。不会安装驱动程序。</li>
<li>NVCC是CUDA的编译器，只是CUDA Toolkit中的一部分</li>
</ul>
<blockquote>
<p>注：CUDA Toolkit完整和不完整的区别：在安装了CUDA Toolkit (Pytorch)后，只要系统上存在与当前的CUDA Toolkit所兼容的Nvidia驱动，则已经编译好的CUDA相关的程序就可以直接运行，不需要重新进行编译过程。如需要为Pytorch框架添加CUDA相关的拓展时（Custom C++ and CUDA Extensions），需要对编写的CUDA相关的程序进行编译等操作，则需安装完整的Nvidia官方提供的CUDA Toolkit。</p>
</blockquote>
<h2 id="4-2-CUDA-Toolkit具体组成"><a href="#4-2-CUDA-Toolkit具体组成" class="headerlink" title="4.2 CUDA Toolkit具体组成"></a>4.2 CUDA Toolkit具体组成</h2><p>一般的结构中，include 包含头文件，bin 包含可执行文件，lib 包含程序实现文件编译生成的library，src包含源代码，doc或help包含文档，samples包含例子。</p>
<ol>
<li>Compiler：NVCC</li>
<li>Tools：分析器profiler、调试器debuggers等</li>
<li>Libraries：科学库和实用程序库</li>
<li>CUDA Samples：CUDA和library API的代码示例</li>
<li>CUDA Driver：驱动，需要与“有CUDA功能的GPU”和“CUDA”都兼容。CUDA工具包都对应一个最低版本的CUDA Driver，CUDA Driver向后兼容。</li>
</ol>
<h2 id="4-3-NVCC简介"><a href="#4-3-NVCC简介" class="headerlink" title="4.3 NVCC简介"></a>4.3 NVCC简介</h2><ul>
<li>NVCC其实就是CUDA的编译器，CUDA程序有两种代码， 在cpu上的host代码和在gpu上的device代码。</li>
<li><code>.cu后缀</code>：cuda源文件，包括host和device代码</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">nvcc编译例子</span></span><br><span class="line">nvcc –cuda x.cu –keep</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x.cudafe1.gpu</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x.cudafe2.gpu</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x.cudafe1.cpp</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-4-Runtime-API-CUDA（nvcc-—version）"><a href="#4-4-Runtime-API-CUDA（nvcc-—version）" class="headerlink" title="4.4 Runtime API CUDA（nvcc —version）"></a>4.4 Runtime API CUDA（nvcc —version）</h2><p>对于 Pytorch 之类的深度学习框架而言，其在大多数需要使用 GPU 的情况中只需要使用 CUDA 的动态链接库支持程序的运行( Pytorch 本身与 CUDA 相关的部分是提前编译好的 )，就像常见的可执行程序一样，不需要重新进行编译过程，只需要其所依赖的动态链接库存在即可正常运行。<br>Anaconda 在安装 Pytorch 等会使用到 CUDA 的框架时，会自动为用户安装对应版本的 Runtime API cudatoolkit，其主要包含应用程序在使用 CUDA 相关的功能时所依赖的动态链接库。在安装了 Runtime API cudatoolkit 后，只要系统上存在与当前的Runtime API cudatoolkit 所兼容的 Nvidia 驱动，则已经编译好的 CUDA 相关的程序就可以直接运行，而不需要安装完整的 Nvidia 官方提供的 CUDA Toolkit .</p>
<p>pytorch和cudatoolkit版本并不是一一对应的关系，一个pytorch版本可以有多个cudatoolkit版本与之对应。例如1.5.1版本的pytorch，既可以使用9.2版本的cudatoolkit，也可以使用10.2版本的cudatoolkit。</p>
<p>可以查看pytorch官网对应的：<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p>
<p>只指定pytorch版本来安装不一定是能work的，例如执行conda install pytorch=X.X.X -c pytorch时，conda会自动为你选择合适版本的 Runtime API cudatoolkit。但conda只能保证你的pytorch和cudatoolkit版本一定是对应的，但并不能保证pytorch可以正常使用，因为系统的Nvidia Driver有可能不支持你所安装的cudatoolkit版本。</p>
<p>所以，除非你对你的Nvidia driver版本很有自信，否则，还是先查看系统Driver API CUDA的版本</p>
<p>当然，如果你对pytorch版本有特别的要求，你可以同时指定pytorch和cudatoolkit的版本。如果这两个版本不能兼容，系统会报错</p>
<p>参考链接1：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41094058/article/details/116207333">一文讲清楚CUDA、CUDA toolkit、CUDNN、NVCC关系 - CSDN</a><br>参考链接2：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/91334380">显卡，显卡驱动,nvcc, cuda driver,cudatoolkit,cudnn到底是什么？ - marsggbo的文章 - 知乎</a></p>
<h1 id="5-安装CUDA"><a href="#5-安装CUDA" class="headerlink" title="5 安装CUDA"></a>5 安装CUDA</h1><h2 id="5-1-下载CUDA安装包"><a href="#5-1-下载CUDA安装包" class="headerlink" title="5.1 下载CUDA安装包"></a>5.1 下载CUDA安装包</h2><p>CUDA官方下载链接：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
<p>进入CUDA官方的下载链接后，查找自己需要下载的版本（以CUDA 11.3.1为例）：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180007447-3486066.png" style="zoom:50%"></p>
<p>点击自己需要下载的版本，一次选择操作系统、系统架构、系统版本和安装方式，在这里推荐使用 runfile(local) 的安装方式。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180053406-1868919368.png" style="zoom:70%"></p>
<p>完成上述操作后，网页下方弹出安装的命令，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180121597-1561022275.png"></p>
<h2 id="5-2-执行CUDA安装"><a href="#5-2-执行CUDA安装" class="headerlink" title="5.2 执行CUDA安装"></a>5.2 执行CUDA安装</h2><p>在Ubuntu 20.04 LTS系统的命令行中，按照以下命令进行安装。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步：使用wget命令下载安装包</span></span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda_11.3.1_465.19.01_linux.run`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步：执行安装脚本</span></span><br><span class="line"><span class="built_in">sudo</span> sh cuda_11.3.1_465.19.01_linux.run</span><br></pre></td></tr></table></figure><br>执行上述命令后，等待1分钟左右，系统会弹出安装的协议，问你Do you accept the above EULA? 你需要在后面的光标处，填写accept，然后敲回车。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180226705-241142197.png" style="zoom:50%"></p>
<p>然后系统询问安装的内容，注意！！！ 一定要把Driver驱动这个给去掉（按空格键可以将 X 去掉），如果[ ]内是X说明是要安装的；如果[ ]是空，说明不安装。选择完成后，然后移动至Install 处，敲击回车。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180348780-1133238924.png" style="zoom:50%"></p>
<p>安装完成后，会在<code>/usr/local</code>目录下产生cuda-11.3目录，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122180420130-923035408.png" style="zoom:50%"></p>
<p>这样说明CUDA-11.3版本安装完成了！</p>
<h2 id="5-3-配置环境变量"><a href="#5-3-配置环境变量" class="headerlink" title="5.3 配置环境变量"></a>5.3 配置环境变量</h2><p>使用 vim ~/.bashrc 命令进行编辑，在文件末尾添加下列代码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cuda</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/cuda/bin</span><br></pre></td></tr></table></figure>
<p>然后执行 source ~/.bashrc 刷新文件使其生效。</p>
<h2 id="5-4-CUDA多版本管理"><a href="#5-4-CUDA多版本管理" class="headerlink" title="5.4 CUDA多版本管理"></a>5.4 CUDA多版本管理</h2><p>从图中可以看出，系统安装了11.1、11.3和11.6版本。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2024.cnblogs.com/blog/2609360/202501/2609360-20250122182157980-1256101233.png" style="zoom:50%"></center>

<p>由于环境变量的地址为<code>/usr/local/cuda</code>，且我们可以从图中发现目录下存在一个软链接，即：<code>/usr/local/cuda</code>指向了<code>/usr/local/cuda-11.6</code>链接，说明此时尽管安装了<code>CUDA 11.1</code>和 <code>CUDA 11.3</code>版本，但系统默认的环境版本为<code>11.6</code>。如何进行多版本的切换呢，比如想把CUDA版本切换成<code>11.3</code>版本（但是要保留<code>CUDA 11.1</code>和<code>11.6</code>版本），我们只需要修改软链接即可，将<code>CUDA 11.3</code>的软链接链接到cuda目录下，代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除原有的软链接</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -rf cuda  </span><br><span class="line"><span class="comment"># 将cuda-11.3链接到cuda下</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/local/cuda-11.3 /usr/local/cuda  </span><br></pre></td></tr></table></figure>
<p>软链接重新生成后，使用<code>nvcc -V</code>命令可以查看当前的CUDA版本，如下所示：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2021 NVIDIA Corporation</span><br><span class="line">Built on Sun_Mar_21_19:15:46_PDT_2021</span><br><span class="line">Cuda compilation tools, release 11.3, V11.3.58</span><br><span class="line">Build cuda_11.3.r11.3/compiler.29745058_0</span><br></pre></td></tr></table></figure></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">君恒</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/01/22/Introduce-GPU-in-deep-learning/">http://example.com/2025/01/22/Introduce-GPU-in-deep-learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">君恒的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%A1%AC%E4%BB%B6/">硬件</a><a class="post-meta__tags" href="/tags/GPU/">GPU</a></div><div class="post-share"><div class="social-share" data-image="https://pic1.imgdb.cn/item/67a6af93d0e0a243d4fcdbf0.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/01/17/Introduce-major-computer-hardware/" title="计算机主要硬件介绍"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a60b39d0e0a243d4fc9e8f.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">计算机主要硬件介绍</div></div><div class="info-2"><div class="info-item-1">作为专栏的第一篇文章，我想从计算机硬件的概念开始，后面再介绍各种计算机技术、软件的学习。注意：我这里只是简单介绍硬件概念，可能会涉及一点基本的原理，但不会太过深入各个硬件的内部原理。                                                                                                                  05:51:42                                           计算机硬件基础                                                                                        27.3万                                                                       3564                                      视频                         ...</div></div></div></a><a class="pagination-related" href="/2025/02/04/Hexo-blog-building/" title="Hexo+Github个人博客搭建"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a2133fd0e0a243d4fbd1c6.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Hexo+Github个人博客搭建</div></div><div class="info-2"><div class="info-item-1">1 博客参考教程本博客的制作重点参考了两个视频教程，地址如下： 【零基础搭建个人博客！手把手教你用Hexo+GitHub+Zeabur打造属于你的网站!】- 哔哩哔哩 【第3期：Butterfly主题的基础配置】- 哔哩哔哩 2 一些插件和问题2.1 官方的主题Themes | Hexo  2.2 博客加密与隐藏请参考1：Hexo：建立自己的日记本并隐藏（加密） | 阳小楊  请参考2：【Hexo】文章加密 - 時光心向阳 - CSDN 请参考3：同时支持置顶和隐藏文章的 hexo 生成器插件 - 0o酱 - CSDN 请参考4：无需更改源码！让你的Hexo的文章在首页隐藏 | InsectMk的个人空间  请参考5：Hexo博客 | 加密！给你的文章添加密码 | Justlovesmile’s BLOG  请参考6：Hexo 博客加密插件 hexo-blog-encrypt 教程 - 吴毓佳 -CSDN博客  2.3 博客文章封面的设置请参考1：Hexo  butterfly 自定义文章封面   &amp;&amp;  主页顶部图片更改 - Moqiqiuzi -...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/07/29/Computer-science-crash-course/" title="计算机科学速成课"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a571b3d0e0a243d4fc67da.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-29</div><div class="info-item-2">计算机科学速成课</div></div><div class="info-2"><div class="info-item-1">1 计算机早期历史1.1 计算机的重要性计算机是当今世界的命脉，如果突然关掉所有计算机，那么世界将会直接乱套。我们生活中很多产品也都是依靠计算机生产出来的。所以说，计算机改变了我们生活几乎所有方面，计算机对我们社会的重要性不言而喻。 1.2 计算机的发展略。。。 2 电子计算机上节提到，用于特定场景的计算设备，如制表机，大大提高了企业和政府的工作效率。但是随着社会的发展，交通运输、科学研究甚至航空航天等发展，人民需要计算能力更强的机器。这种计算能力更强的机器，往往体积巨大，耗电量巨大，这为后面的创新埋下伏笔。 2.1...</div></div></div></a><a class="pagination-related" href="/2025/01/17/Introduce-major-computer-hardware/" title="计算机主要硬件介绍"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a60b39d0e0a243d4fc9e8f.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-17</div><div class="info-item-2">计算机主要硬件介绍</div></div><div class="info-2"><div class="info-item-1">作为专栏的第一篇文章，我想从计算机硬件的概念开始，后面再介绍各种计算机技术、软件的学习。注意：我这里只是简单介绍硬件概念，可能会涉及一点基本的原理，但不会太过深入各个硬件的内部原理。                                                                                                                  05:51:42                                           计算机硬件基础                                                                                        27.3万                                                                       3564                                      视频                         ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a1e626d0e0a243d4fbcc56.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">君恒</div><div class="author-info-description">我的博客我做主</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wang-jun-heng"><i class="fab fa-github"></i><span>Follow My Github</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/wang-jun-heng" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:junheng.wang@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到君恒的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E7%94%A8%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84GPU%E4%BB%8B%E7%BB%8D"><span class="toc-text">1 用于深度学习的GPU介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E7%9B%AE%E5%89%8D%E5%B8%B8%E7%94%A8%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84GPU%E5%9E%8B%E5%8F%B7%E5%92%8C%E6%80%A7%E8%83%BD%E5%8F%82%E6%95%B0"><span class="toc-text">1.1 目前常用于深度学习的GPU型号和性能参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E6%98%BE%E5%8D%A1%E9%80%89%E8%B4%AD%E5%BB%BA%E8%AE%AE"><span class="toc-text">1.2 显卡选购建议</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-%E5%85%A5%E9%97%A8%E7%BA%A7-%E5%88%9D%E5%AD%A6%E8%80%85%E6%88%96%E8%BD%BB%E5%BA%A6%E7%94%A8%E6%88%B7"><span class="toc-text">1.2.1 入门级 - 初学者或轻度用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-%E4%B8%AD%E7%BA%A7-%E7%A0%94%E7%A9%B6%E5%91%98%E6%88%96%E5%BC%80%E5%8F%91%E8%80%85"><span class="toc-text">1.2.2 中级 - 研究员或开发者</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-3-%E9%AB%98%E7%BA%A7-%E4%B8%93%E4%B8%9A%E7%BA%A7-%E9%AB%98%E7%AB%AF%E7%A0%94%E7%A9%B6%E6%9C%BA%E6%9E%84%E6%88%96%E4%BC%81%E4%B8%9A"><span class="toc-text">1.2.3 高级&#x2F;专业级 - 高端研究机构或企业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-CUDA%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D"><span class="toc-text">2 CUDA概念介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E8%BD%AC%E8%BD%BD%E8%87%AA%E5%85%B6%E4%BB%96%E7%BD%91%E7%AB%99%E7%9A%84Cuda%E6%A6%82%E5%BF%B5"><span class="toc-text">2.1 转载自其他网站的Cuda概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E5%85%B3%E4%BA%8EBrookGPU%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-text">2.2 关于BrookGPU的介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-BrookGPU%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">2.2.1 BrookGPU是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-BrookGPU%E7%9A%84%E5%BA%95%E5%B1%82%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="toc-text">2.2.2 BrookGPU的底层源代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%90%84GPU%E6%94%AF%E6%8C%81%E7%9A%84CUDA%E7%89%88%E6%9C%AC"><span class="toc-text">3 各GPU支持的CUDA版本</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="toc-text">3.1 查看显卡驱动版本号</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E6%9F%A5%E7%9C%8B%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E7%89%88%E6%9C%AC%E5%8F%B7%E5%92%8CCUDA%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-text">3.2 查看显卡驱动版本号和CUDA版本对应关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E6%9F%A5%E7%9C%8B%E7%BB%8F%E5%85%B8%E7%9A%84CUDA%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="toc-text">3.3 查看经典的CUDA版本号</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-%E5%B0%8F%E7%BB%93"><span class="toc-text">3.4 小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-CUDA%E3%80%81CUDA-toolkit%E3%80%81CUDNN%E3%80%81NVCC%E5%85%B3%E7%B3%BB"><span class="toc-text">4 CUDA、CUDA toolkit、CUDNN、NVCC关系</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-CUDA-cudnn-CUDA-Toolkit-NVCC%E5%8C%BA%E5%88%AB%E7%AE%80%E4%BB%8B"><span class="toc-text">4.1 CUDA&#x2F;cudnn&#x2F;CUDA Toolkit&#x2F;NVCC区别简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-CUDA-Toolkit%E5%85%B7%E4%BD%93%E7%BB%84%E6%88%90"><span class="toc-text">4.2 CUDA Toolkit具体组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-NVCC%E7%AE%80%E4%BB%8B"><span class="toc-text">4.3 NVCC简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Runtime-API-CUDA%EF%BC%88nvcc-%E2%80%94version%EF%BC%89"><span class="toc-text">4.4 Runtime API CUDA（nvcc —version）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E5%AE%89%E8%A3%85CUDA"><span class="toc-text">5 安装CUDA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E4%B8%8B%E8%BD%BDCUDA%E5%AE%89%E8%A3%85%E5%8C%85"><span class="toc-text">5.1 下载CUDA安装包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E6%89%A7%E8%A1%8CCUDA%E5%AE%89%E8%A3%85"><span class="toc-text">5.2 执行CUDA安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-text">5.3 配置环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-CUDA%E5%A4%9A%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86"><span class="toc-text">5.4 CUDA多版本管理</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/10/Learn-Github/" title="Github的学习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67aa1512d0e0a243d4fe0794.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Github的学习"/></a><div class="content"><a class="title" href="/2025/02/10/Learn-Github/" title="Github的学习">Github的学习</a><time datetime="2025-02-10T08:48:09.000Z" title="发表于 2025-02-10 16:48:09">2025-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/08/Common-math-formulas/" title="常用数学公式"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a767e2d0e0a243d4fd1dd4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="常用数学公式"/></a><div class="content"><a class="title" href="/2025/02/08/Common-math-formulas/" title="常用数学公式">常用数学公式</a><time datetime="2025-02-08T14:04:14.000Z" title="发表于 2025-02-08 22:04:14">2025-02-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/06/Power-of-electrical-equipment/" title="常见用电设备功率(未完结)"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a43aafd0e0a243d4fc1b0a.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="常见用电设备功率(未完结)"/></a><div class="content"><a class="title" href="/2025/02/06/Power-of-electrical-equipment/" title="常见用电设备功率(未完结)">常见用电设备功率(未完结)</a><time datetime="2025-02-06T03:44:59.000Z" title="发表于 2025-02-06 11:44:59">2025-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/04/Hexo-blog-building/" title="Hexo+Github个人博客搭建"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a2133fd0e0a243d4fbd1c6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo+Github个人博客搭建"/></a><div class="content"><a class="title" href="/2025/02/04/Hexo-blog-building/" title="Hexo+Github个人博客搭建">Hexo+Github个人博客搭建</a><time datetime="2025-02-04T06:53:08.000Z" title="发表于 2025-02-04 14:53:08">2025-02-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/22/Introduce-GPU-in-deep-learning/" title="深度学习中的显卡介绍"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.imgdb.cn/item/67a6af93d0e0a243d4fcdbf0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习中的显卡介绍"/></a><div class="content"><a class="title" href="/2025/01/22/Introduce-GPU-in-deep-learning/" title="深度学习中的显卡介绍">深度学习中的显卡介绍</a><time datetime="2025-01-22T02:46:16.000Z" title="发表于 2025-01-22 10:46:16">2025-01-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By 君恒</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="请输入搜索内容" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>